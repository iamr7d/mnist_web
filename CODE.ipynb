{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahulrajpvr7d\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Training Progress:  10%|█         | 1/10 [00:06<00:57,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Accuracy: 0.9333, Validation Accuracy: 0.9763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|██        | 2/10 [00:11<00:47,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Accuracy: 0.9821, Validation Accuracy: 0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  30%|███       | 3/10 [00:17<00:40,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Accuracy: 0.9876, Validation Accuracy: 0.9867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  40%|████      | 4/10 [00:23<00:35,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Accuracy: 0.9901, Validation Accuracy: 0.9887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  50%|█████     | 5/10 [00:29<00:29,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Accuracy: 0.9929, Validation Accuracy: 0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  60%|██████    | 6/10 [00:36<00:24,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Accuracy: 0.9941, Validation Accuracy: 0.9883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  70%|███████   | 7/10 [00:42<00:18,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Accuracy: 0.9945, Validation Accuracy: 0.9907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  80%|████████  | 8/10 [00:48<00:11,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Accuracy: 0.9963, Validation Accuracy: 0.9918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  90%|█████████ | 9/10 [00:53<00:05,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Accuracy: 0.9970, Validation Accuracy: 0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 10/10 [00:59<00:00,  5.93s/it]\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Accuracy: 0.9964, Validation Accuracy: 0.9923\n",
      "Model saved as mnist_digit_recognizer_model.h5\n",
      "Test set accuracy: 0.9905999898910522\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Importing Necessary Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm  # for progress tracking\n",
    "\n",
    "# Step 2: Loading and Preprocessing the MNIST Dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist['data'], mnist['target'].astype(np.int8)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "X = X / 255.0\n",
    "\n",
    "# Reshape X to fit CNN input requirements (samples, width, height, channels)\n",
    "X = X.values.reshape(-1, 28, 28, 1)  # -1 infers sample size, 1 channel for grayscale\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "y = to_categorical(y, 10)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=10000, random_state=42)\n",
    "\n",
    "# Step 3: Building the CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # 10 classes for digits 0-9\n",
    "])\n",
    "\n",
    "# Step 4: Compiling the Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Training the Model with Progress Tracking\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Wrapping model.fit in tqdm\n",
    "with tqdm(total=epochs, desc=\"Training Progress\") as pbar:\n",
    "    for epoch in range(epochs):\n",
    "        # Train the model\n",
    "        history = model.fit(X_train, y_train, batch_size=batch_size, epochs=1, validation_split=0.1, verbose=0)\n",
    "        \n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n",
    "        # Print accuracy and loss for each epoch\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, \"\n",
    "              f\"Train Accuracy: {history.history['accuracy'][0]:.4f}, \"\n",
    "              f\"Validation Accuracy: {history.history['val_accuracy'][0]:.4f}\")\n",
    "\n",
    "# Step 6: Saving the Model\n",
    "model.save(r\"C:\\Users\\rahulrajpvr7d\\OneDrive\\Desktop\\MNIST\\MODEL\\model.h5\")\n",
    "print(\"Model saved as mnist_digit_recognizer_model.h5\")\n",
    "\n",
    "# Step 7: Evaluating the Model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test set accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahulrajpvr7d\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Training Progress:  10%|█         | 1/10 [00:06<01:00,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Accuracy: 0.9366, Validation Accuracy: 0.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|██        | 2/10 [00:12<00:48,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Accuracy: 0.9817, Validation Accuracy: 0.9868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  30%|███       | 3/10 [00:18<00:41,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Accuracy: 0.9876, Validation Accuracy: 0.9880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  40%|████      | 4/10 [00:23<00:34,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Accuracy: 0.9909, Validation Accuracy: 0.9888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  50%|█████     | 5/10 [00:29<00:28,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Accuracy: 0.9923, Validation Accuracy: 0.9913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  60%|██████    | 6/10 [00:34<00:22,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Accuracy: 0.9941, Validation Accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  70%|███████   | 7/10 [00:40<00:17,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Accuracy: 0.9950, Validation Accuracy: 0.9917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  80%|████████  | 8/10 [00:46<00:11,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Accuracy: 0.9964, Validation Accuracy: 0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  90%|█████████ | 9/10 [00:53<00:05,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Accuracy: 0.9964, Validation Accuracy: 0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 10/10 [00:59<00:00,  5.91s/it]\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Accuracy: 0.9971, Validation Accuracy: 0.9908\n",
      "Model saved in .h5 and SavedModel formats.\n",
      "Test set loss: 0.0369, Test set accuracy: 0.9886\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Importing Necessary Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm  # for progress tracking\n",
    "\n",
    "# Step 2: Loading and Preprocessing the MNIST Dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist['data'], mnist['target'].astype(np.int8)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "X = np.array(X) / 255.0  # Convert to numpy array\n",
    "X = X.reshape(-1, 28, 28, 1)  # Reshape to fit CNN input requirements\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "y = to_categorical(y, 10)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=10000, random_state=42)\n",
    "\n",
    "# Step 3: Building the CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # 10 classes for digits 0-9\n",
    "])\n",
    "\n",
    "# Step 4: Compiling the Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Training the Model with Progress Tracking\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Wrapping model.fit in tqdm\n",
    "with tqdm(total=epochs, desc=\"Training Progress\") as pbar:\n",
    "    for epoch in range(epochs):\n",
    "        # Train the model\n",
    "        history = model.fit(X_train, y_train, batch_size=batch_size, epochs=1, validation_split=0.1, verbose=0)\n",
    "        \n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n",
    "        # Print accuracy and loss for each epoch\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, \"\n",
    "              f\"Train Accuracy: {history.history['accuracy'][0]:.4f}, \"\n",
    "              f\"Validation Accuracy: {history.history['val_accuracy'][0]:.4f}\")\n",
    "\n",
    "# Step 6: Saving the Model\n",
    "model.save(r\"C:\\Users\\rahulrajpvr7d\\OneDrive\\Desktop\\MNIST\\MODEL\\model.h5\")\n",
    "model.save(r\"C:\\Users\\rahulrajpvr7d\\OneDrive\\Desktop\\MNIST\\MODEL\\model_saved.h5\")  # SavedModel format\n",
    "print(\"Model saved in .h5 and SavedModel formats.\")\n",
    "\n",
    "# Step 7: Evaluating the Model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test set loss: {test_loss:.4f}, Test set accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
